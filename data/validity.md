# Threats to Validity

To ensure the methodological rigor of our study, we adhered to the guidelines proposed by Ampatzoglou et al. (AmpatzoglouEtAl2020). These guidelines provide a structured approach for identifying and reporting potential TTVs, allowing for a more transparent and systematic assessment of the study’s limitations. By following this framework, we aim to enhance the reliability of our findings and ensure that any biases or constraints are explicitly acknowledged and addressed.These threats are categorized into three key areas:

- **Study Selection Validity:** Evaluates whether the search process comprehensively identifies relevant studies, considers diverse sources, manages duplicates, and appropriately includes or excludes literature.

- **Data Validity:** Assesses sample size adequacy, variable selection, publication sources, statistical analysis, data quality, and potential biases in data extraction and interpretation.

- **Research Validity:** Examines the reliability and repeatability of the research process, the appropriateness of the chosen method, the alignment of research questions with study goals, familiarity with the field, and the generalizability of results.

Therefore, we believe that by addressing these aspects, we enhance the transparency and reliability of our findings.


## Internal

In our study, we decided to use only the SCOPUS database for selecting studies. This choice was made due to its extensive coverage of relevant journals and conferences, as well as its status as one of the leading indexing databases in the scientific literature. We acknowledge that using a single database may introduce a selection bias, as some relevant studies may be indexed only in other platforms. To mitigate this bias, we followed a rigorous process of defining inclusion and exclusion criteria, ensuring transparency and reproducibility in the study selection. Similar studies (CruzEtAl2018) (FasciglioneEtAl2022) (EspinosaEtAl2018) that used the SCOPUS database provide examples of consistent results. However, we suggest that future research expand the search to include other databases

Another threat related to study selection is the absence of manual search techniques, such as snowballing (searching for cited references or studies that cite the selected papers). We chose not to apply this approach because it could introduce older studies, diverting the focus of our review. Our goal is to analyze the current status of TTVs in replication studies, emphasizing the most recent research. To reinforce this strategy, we also restricted our search to the past three years, ensuring that the analyzed data reflect current trends and challenges in the replication literature. This limitation allows us to maintain an updated perspective, avoiding the inclusion of studies that may not represent the most recent scenario.

A potential validity threat in replication studies is variable confusion. When comparing an original study with its replication, natural differences may arise, such as variations in the environment, sample profile, or applied methodology. To mitigate this threat, we used standardized criteria with well-defined guidelines to identify and categorize TTVs, ensuring a systematic approach and reducing subjective interpretations.

A significant validity threat in review studies is systematic error in data extraction, which occurs when there are inconsistencies or biases in the manual data collection process from articles. This issue can compromise the accuracy and reliability of the results. Such errors may arise due to various factors, including subjective interpretations, lack of standardization, and confirmation bias among researchers. To mitigate this threat, we applied a detailed data extraction protocol with clear and objective criteria. Data extraction was performed independently by two researchers, with discussions on any discrepancies. We also used standardized forms for data collection and ensured that both researchers involved in the data extraction process understood and applied the same established guidelines.

Another internal threat arises from how studies describe TTVs inconsistently. For example, while some articles provide detailed explanations of potential methodological weaknesses, others mention these threats only superficially or even omit them entirely. This bias can impact the comparative analysis of results, compromising the interpretation of findings. To mitigate this threat, in addition to a quantitative analysis of the categorization of reported TTVs, we considered only studies with a dedicated TTV section for our qualitative analysis.

Another relevant threat is evaluation bias for TTV Level of Detail, since the studies were analyzed manually. To mitigate this risk, the evaluations were conducted blindly, meaning that the reviewers did not have access to the authors’ identities or the origin of the studies. Additionally, to assess the consistency between reviewers, the Cohen’s Kappa coefficient was calculated.

## External

A relevant threat to the external validity of the study is improper generalization. This issue arises when most of the analyzed replicated studies belong to a single type of environment—either academic or industrial—making the conclusions potentially inapplicable to the other context. To address this threat, we categorized each study [REP] and [ORI] as either academic or industrial, following the OECD (OECD2015) guidelines. This allows for a differentiated analysis of the results according to the context, thereby preventing undue extrapolation of conclusions from one environment to another. We acknowledge this limitation and suggest that further studies in different settings would be necessary to validate or complement our findings in case of discrepancies between environments.

Another external threat to the study is the lack of methodological diversity. This issue occurs when most of the analyzed studies adopt a single type of approach, such as Experimental Methods or Surveys, making the conclusions potentially inapplicable to other methods like Case Studies, Action Research, or Ethnography. This limitation can affect the understanding of the investigated reality, as different methods provide complementary perspectives on a phenomenon. To mitigate this threat, we categorized the studies according to the research method used, enabling a differentiated analysis of the findings based on the adopted approach. This prevents improper extrapolation of conclusions to underrepresented methods. This limitation suggests the need for future investigations using diverse methods to validate and expand the applicability of the results.

In question Q2, while testing the Hypothesis for the Standardization in Reporting Threats to Validity, the scale was applied exclusively to studies that included an explicit TTV section. Although this approach aligns with our objective, it may limit the generalizability of the results, as it does not account for studies in which threats to validity are discussed in a dispersed or implicit manner throughout the text.

## Construct
A potential threat to the consistency of the analysis is the ambiguity in categorizing TTVs. The distinction between internal, external, construct, and conclusion validity can be subjective, as some threats exhibit characteristics that overlap multiple categories. This subjectivity can lead to inconsistencies in classification, making comparisons between studies more difficult and affecting the accuracy of conclusions.

To mitigate this threat, we adopted the classification proposed by Wohlin et al. (Wohlin2000) as a reference, ensuring a standardized criterion for categorizing threats and minimizing divergent interpretations. Additionally, we incorporated a peer review process into our research protocol, in which two researchers independently analyzed and validated the categorization of threats. This approach helps enhance the reliability of classification and reduces the impact of potential individual biases.

A threat to construct in this review is the lack of clarity in defining the type of replication in the analyzed studies. Many studies do not specify whether the replication performed is internal, external, close, differentiated, or conceptual, making it difficult to accurately categorize the studies and potentially compromising the validity of the conclusions. This lack of detail can lead to inconsistencies in the analysis, as different interpretations of the nature of the replication may result in divergent classifications. To mitigate this threat, we adopted standardized criteria for categorizing replicated studies, following the guidelines of Baldassarre et al. (BaldassarreEtAl2014). This strategy helps reduce the impact of subjectivity in the analysis and increases the reliability of the findings.

Another threat related to the TTV Level of Detail concerns the risk that the adopted scale may not accurately measure the intended construct. Despite the clear definition of each level, there is a certain degree of subjectivity in the interpretation of terms. To mitigate this bias, the two reviewers discussed the scale in advance to align their understanding, following the guidelines of Wohlin et al. (2000).

## Conclusion

A TTVs of the results is the possibility of statistical errors in correlation analysis. If the statistical methods used to associate the research method with the number or type of reported threats are inadequate, the findings may be distorted, leading to misleading conclusions. To mitigate this threat, we aimed to select appropriate statistical methods, such as Spearman's Correlation and the Wilcoxon Test. Additionally, we chose Jamovi as our statistical tool due to its practicality, helping to minimize the risk of errors and increase reliability. If there are too few replicated studies in certain categories (e.g., specific types of replication or research methods), the results may be inconclusive. To address this, we will report potential limitations in the statistical analysis and avoid overgeneralizations.

Another conclusion validity threat is the reliability of the analysis, particularly the subjective interpretation of qualitative data. Since the categorization of validity threats relies on human judgment, there is a risk of bias in coding and data analysis. Researchers may interpret the same threats differently, leading to inconsistencies in classification and making cross-study comparisons difficult. Additionally, subjectivity can influence the identification and perceived relevance of certain threats, impacting the study’s conclusions. To mitigate this threat, we adopted the classification proposed by Wohlin et al. (Wohlin2000). Furthermore, we implemented a peer review process in our research protocol, where independent reviewers discussed discrepancies until reaching a consensus, considering only those threats explicitly reported.

A potential threat to the comprehensiveness of this systematic review's findings is the limitation of the search to the SCOPUS database. Relevant studies not indexed in this database may have been excluded, leading to a limited literature coverage that affects the generalizability and representativeness of the findings. Silva et al. (SilvaEtAl2014) argue that the scope of a literature search is an inherent validity threat in any review, whether systematic or not. Achieving complete coverage of the available literature is virtually impossible, and accurately estimating the degree of coverage achieved by a review is a significant challenge. Even with extensive search strategies, there is always a possibility that relevant studies may not be included in the analysis.

